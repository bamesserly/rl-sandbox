{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07524bed",
   "metadata": {},
   "source": [
    "# Shower Temperature Beginner Reinforcement Learning Example\n",
    "\n",
    "This script implements the Bellman equation to train a Q table and test it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cbf14",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "0. [Intro](#intro)\n",
    "1. [Explore Shower Environment](#environment)\n",
    "2. [Update Q-Table Function](#update_q_table)\n",
    "3. [Train and Test Function](#train_and_test)\n",
    "4. [Do the training and testing](#run)\n",
    "5. [Visualize and Optimize Learning](#visualize_and_optimize)\n",
    "    1. [How Many Training Episodes is Good Enough?](#episodes)\n",
    "    2. [Find Optimal Training Parameters with a Grid Search](#grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218d672",
   "metadata": {},
   "source": [
    "## 0. Intro <a name=\"intro\"></a>\n",
    "The \"game\" that this environment implements is that you're taking a shower and you want the temperature to stay around a nice temperature.\n",
    "\n",
    "For each second of a shower of a certain length, you can move the temperature up or down one degree.\n",
    "\n",
    "You are rewarded after each second if your shower stays within a temperature sweet spot. You're punished if you're outside that sweet spot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594397c8",
   "metadata": {},
   "source": [
    "## 1. Explore Shower Environment <a name=\"environment\"></a>\n",
    "This environment resembles the openai-gym or google's TF-Agents environments with `step`, `render`, and `reset` functions. In fact this environment inherits from open-ai gym's `Env` class, though it doesn't currently use any of its parent's features.\n",
    "\n",
    "Here, sample the observation and actions spaces and run a few showers with random decision making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6a1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shower_environment import Shower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd8e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random valid temperature: 0\n",
      "Random valid temperature change: -1\n",
      "\n",
      "A few random showers:\n",
      "Episode: 1 Score: 10\n",
      "Episode: 2 Score: -60\n",
      "Episode: 3 Score: -58\n",
      "Episode: 4 Score: -60\n",
      "Episode: 5 Score: -60\n"
     ]
    }
   ],
   "source": [
    "env = Shower()\n",
    "\n",
    "print(\"Random valid temperature:\", env.observation_space.sample())\n",
    "print(\"Random valid temperature change:\", env.action_space.sample()-1)\n",
    "\n",
    "print(\"\\nA few random showers:\")\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print(f\"Episode: {episode} Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3944b",
   "metadata": {},
   "source": [
    "## 2. Update Q-table function <a name=\"update_q_table\"></a>\n",
    "This function will be called during training to populate the Q-table based on the Bellman equation. The Q-table will be then used during testing to make decisions about how to change the temperature at each shower step.\n",
    "Arguments:\n",
    "* a starting state and a finishing state (i.e. just the temperature at step n and the temperature at step n+1)\n",
    "* the action that took us from temperature at step n to temperature at step n+1 (i.e. up 1 degree, down 1 degree, up 0 degrees)\n",
    "* and the reward assigned to the action/final state\n",
    "\n",
    "And here's wikipedia on the two parameters, the learning (alpha) and discount (gamma) rates:\n",
    "\n",
    "> **Learning rate** -- The learning rate or step size determines to what extent newly acquired information overrides old information. A factor of 0 makes the agent learn nothing (exclusively exploiting prior knowledge), while a factor of 1 makes the agent consider only the most recent information (ignoring prior knowledge to explore possibilities). **In fully deterministic environments, a learning rate of alpha = 1 is optimal.** When the problem is stochastic, the algorithm converges under some technical conditions on the learning rate that require it to decrease to zero. In practice, often a constant learning rate is used...\n",
    "\n",
    "> **Discount factor** -- The discount factor determines the importance of future rewards. A factor of 0 will make the agent \"myopic\" (or short-sighted) by only considering current rewards ... while a factor approaching 1 will make it strive for a long-term high reward. If the discount factor meets or exceeds 1, the action values may diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5665a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c0d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(params, q_table, state_i, state_f, action, step_reward):\n",
    "    try:\n",
    "        # note about 2d np array access:\n",
    "        # q_table[state_i] accesses the state_i-th row, which is an array with\n",
    "        # length equal to number of actions.\n",
    "        # q_table[state_i, action] access the action-th element of the state_ith\n",
    "        # array.\n",
    "        old_q_value = q_table[state_i, action]\n",
    "    except IndexError:\n",
    "        print(\"ERROR with q_table\")\n",
    "        print(q_table)\n",
    "        print(state_i, action)\n",
    "        return None\n",
    "    \n",
    "    # max q value given the state after this temp change\n",
    "    next_max = np.max(q_table[state_f])\n",
    "    q_target = step_reward + params['gamma'] * next_max\n",
    "    q_delta = q_target - old_q_value\n",
    "    q_table[state_i, action] = old_q_value + params['alpha'] * q_delta\n",
    "    \n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a9ee0",
   "metadata": {},
   "source": [
    "## 3. Train and test function <a name=\"train_and_test\"></a>\n",
    "This function simulates `n_episodes` of showers. In `do_train` mode, it uses random decision making and populates the Q-table. In test mode, it uses a given Q-table to make decisions and does not update the Q-table.\n",
    "\n",
    "Return the Q-table that was filled/used and the average reward over all the showers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e39ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha - learning rate\n",
    "# gamma - discount rate\n",
    "# epsilon - exploration threshold (not currently used)\n",
    "default_params = {'alpha' : 0.9, 'gamma' : 1., 'epsilon' : 0.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87fcb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop showers\n",
    "def train_test(env, in_q_table, n_episodes = 200, do_train = True, params = default_params):\n",
    "    q_table = in_q_table.copy()\n",
    "    total_reward = 0\n",
    "    for i_shower in range(n_episodes):\n",
    "        done = False\n",
    "        env.reset()\n",
    "        state_i = env.state\n",
    "        shower_reward = 0\n",
    "        #print(i_shower)\n",
    "        while not done:\n",
    "            # choose action\n",
    "            action = env.action_space.sample() if do_train else np.argmax(q_table[state_i])\n",
    "\n",
    "            # take a step\n",
    "            state_f, reward, done, info = env.step(action)\n",
    "            #print(\"  \", env.shower_time, state, reward, done)\n",
    "            try:\n",
    "                assert state_f in env.observation_space\n",
    "            except AssertionError:\n",
    "                print(\"Invalid state obtained\", state_f, i_shower, env.shower_time, action)\n",
    "                break\n",
    "                                        \n",
    "            # update q table\n",
    "            if do_train:\n",
    "                q_table = update_q_table(params, q_table, state_i, state_f, action, reward)\n",
    "\n",
    "            # increment reward\n",
    "            shower_reward += reward\n",
    "\n",
    "            state_i = state_f\n",
    "            \n",
    "        #print(\"  Shower reward:\", shower_reward)\n",
    "        total_reward += shower_reward\n",
    "\n",
    "    #np.savetxt(\"qtable.csv\", q_table, delimiter=\",\")\n",
    "    avg_reward = total_reward / n_episodes\n",
    "    return q_table, avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8c83d",
   "metadata": {},
   "source": [
    "## 4. Do the Training and Testing <a name=\"run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ac6e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial q table full of zeroes\n",
    "init_q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88dda035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: -39.0\n"
     ]
    }
   ],
   "source": [
    "# Train for 2 episodes\n",
    "env = Shower()\n",
    "q_table, avg_reward = train_test(env, init_q_table, n_episodes = 2, do_train = True)\n",
    "print(f\"average reward: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbb7db-525f-4177-95f2-3d73ca6b1dc7",
   "metadata": {},
   "source": [
    "Here's a snippet of a random trained q_table after 2 episodes.\n",
    "```\n",
    "       [0.         ,  0.        ,  0.        ],\n",
    "       ...\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        , -0.9       , -0.99      ],\n",
    "       [-0.99      ,  0.        , -1.962     ],\n",
    "       [-0.99      , -1.9809909 , -2.88018   ],\n",
    "       [-1.98099909, -2.791801  , -1.89099   ],\n",
    "       [-2.801844  , -1.89      , -0.99      ],\n",
    "       [-1.962     , -0.9       ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  2.439     ,  5.78691   ],\n",
    "       [ 4.9599    ,  3.51      ,  8.04880017],\n",
    "       [ 5.63949   ,  3.348     ,  9.04558011],\n",
    "       [ 8.22739887,  1.8       ,  3.42      ],\n",
    "       [ 2.61      ,  3.42      ,  1.65942   ],\n",
    "       [ 4.24719   , -0.9       , -0.99      ],\n",
    "       [ 1.43271   , -1.89      , -0.999     ],\n",
    "       [-0.999     , -0.99      ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       [ 0.        ,  0.        ,  0.        ],\n",
    "       ...\n",
    "       [0.         ,  0.        ,  0.        ]\n",
    "```\n",
    "The rows represent temperatures. The columns represent actions (lower, hold, raise), and the contents represent scores for those (action, temperature) pairs.\n",
    "\n",
    "* The rows of zeroes above and below the center populated region show that we never encountered those temperatures during training, so the q values are still at their default of 0.\n",
    "* The lower and upper edges of the populated region all have negative values. It was determined (somewhat incorrectly) that no decision in these regions was good. Seems like we need some more long-term thinking, and we should tweak the discount factor.\n",
    "* In the central region, as with the edges, we see lots of positive values, indicating that it's just good to be in this region and that no decision is bad.\n",
    "* We would expect, in the rows representing the edges of the goldilocks region to have positive q values for actions moving you in to the goldilocks regions, and negative for moving you out. And also high scores for any decision inside of the goldilocks region. Maybe we're seeing some of this, but more training and rewards tweaking is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029e1816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: -36.88\n",
      "average reward: -31.24\n",
      "average reward: -38.16\n"
     ]
    }
   ],
   "source": [
    "# Test – how does our (inadequately-trained) table perform?\n",
    "avg_reward = train_test(env, q_table, n_episodes = 100, do_train = False)[1]\n",
    "print(f\"average reward: {avg_reward}\")\n",
    "avg_reward = train_test(env, q_table, n_episodes = 100, do_train = False)[1]\n",
    "print(f\"average reward: {avg_reward}\")\n",
    "avg_reward = train_test(env, q_table, n_episodes = 100, do_train = False)[1]\n",
    "print(f\"average reward: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b960d4",
   "metadata": {},
   "source": [
    "## 5. Visualize and optimize some parameters <a name=\"visualize_and_optimize\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c06e3",
   "metadata": {},
   "source": [
    "### A. How Many Training Episodes is Good Enough? <a name=\"episodes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f566eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 training episodes – average reward: 20.02\n",
      "20 training episodes – average reward: 48.96\n",
      "30 training episodes – average reward: 54.4\n",
      "40 training episodes – average reward: 54.28\n",
      "50 training episodes – average reward: 55.96\n",
      "60 training episodes – average reward: 55.12\n",
      "70 training episodes – average reward: 54.3\n",
      "80 training episodes – average reward: 55.14\n",
      "90 training episodes – average reward: 54.26\n"
     ]
    }
   ],
   "source": [
    "episodes = range(2,100,2)\n",
    "rewards = []\n",
    "for e in episodes:\n",
    "    env = Shower()\n",
    "    q_table = train_test(env, init_q_table, n_episodes = e, do_train = True)[0]\n",
    "    avg_reward = train_test(env, q_table, n_episodes = 100, do_train = False)[1]\n",
    "    if e % 10 == 0: \n",
    "        print(f\"{e} training episodes – average reward: {avg_reward}\")\n",
    "    rewards.append(avg_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8a848-b702-49d3-a1ab-f9643859255a",
   "metadata": {},
   "source": [
    "And here's an updated snippet of a fully trained table.\n",
    "```\n",
    "       [  0.        ,   0.        ,   0.        ],\n",
    "       ...\n",
    "       [  0.        ,   0.        ,   0.        ],\n",
    "       [  0.        ,   0.        ,  -0.9       ],\n",
    "       [ -0.9       ,  -0.9       ,  -0.9       ],\n",
    "       [ -0.9       ,  -0.9       ,   0.        ],\n",
    "       [ -0.9       ,  -1.809     ,  28.49900963],\n",
    "       [ -1.80999   ,  35.9342987 ,  36.97207978],\n",
    "       [ 35.96096884,  37.88811935,  78.57399555],\n",
    "       [ 38.12830487,  83.15737332, 176.01796288],\n",
    "       [ 83.57566839, 185.02688814, 187.16961324],\n",
    "       [186.14149708, 187.49418128, 241.74084734],\n",
    "       [235.41911116, 259.55709776, 264.34299263],\n",
    "       [263.26866923, 189.53685332, 265.37398727],\n",
    "       [264.06404117, 247.35452374, 266.56255314],\n",
    "       [265.43327242, 266.76717269, 267.7865623 ],\n",
    "       [266.75461185, 267.79664878, 270.84457776],\n",
    "       [269.83089552, 268.79878853, 271.85313259],\n",
    "       [270.85213516, 273.35071338, 274.35072835],\n",
    "       [273.20064232, 274.50072655, 275.51723338],\n",
    "       [274.51716044, 275.51724797, 276.51724959],\n",
    "       [275.35515226, 276.3349731 , 277.6973395 ],\n",
    "       [276.69668839, 276.6975196 , 276.79960825],\n",
    "       [277.55792043, 275.89760887, 270.03566386],\n",
    "       [268.55469309, 271.8093068 , 270.00072763],\n",
    "       [269.52680288, 269.95557404, 263.0425605 ],\n",
    "       [262.16676954, 263.06091359, 262.56517662],\n",
    "       [263.85520285, 250.30889391, 259.4710608 ],\n",
    "       [261.60143171, 260.48661541, 257.45336513],\n",
    "       [259.47105916, 257.42502104, 247.20201845],\n",
    "       [257.44885236, 246.77985635, 239.80510546],\n",
    "       [246.49447994, 214.20291456, 213.2028322 ],\n",
    "       [214.20290116, 213.18012256, 212.19327786],\n",
    "       [213.1990518 , 211.573488  , 211.00493743],\n",
    "       [212.19183993, 211.11473351, 209.22956588],\n",
    "       [211.09488433, 206.59181871, 177.07813375],\n",
    "       [204.03766397, 177.07813599, 168.10417467],\n",
    "       [176.65844874, 171.84340914, 132.73482134],\n",
    "       [168.06984327, 132.76453742, 128.50160545],\n",
    "       [132.44371699, 127.09787625, 114.07868635],\n",
    "       [127.20416565,  92.13047745,  -2.6289    ],\n",
    "       [ -1.98972   ,  -2.7       ,  -1.89099   ],\n",
    "       [ -2.70981   ,  -0.99      ,  -1.899     ],\n",
    "       [ -1.9872    ,  -0.9       ,  -1.809     ],\n",
    "       [ -0.99      ,  -0.9       ,  -1.9791    ],\n",
    "       [ -1.881     ,  -1.890999  ,  -0.999     ],\n",
    "       [ -0.99      ,  -0.999     ,   0.        ],\n",
    "       [  0.        ,   0.        ,   0.        ],\n",
    "       [  0.        ,   0.        ,   0.        ],\n",
    "       ...\n",
    "       [  0.        ,   0.        ,   0.        ],\n",
    "```\n",
    "The desired temperature range is only 4 degrees (38+/-2). Why are the rows above and below that all positives? The answer is that we choose an action, given a row, based on the `max` value. We don't need and shouldn't expect to see a large distinction between good and bad decisions in a row. After long enough training, the whole table will be large positive numbers.\n",
    "\n",
    "Let's make sure a few random rows make sense, though. The table indeed peaks at row 38. The max values for the entire table appear on rows 37 and 39 at the actions to increase one deg and decrease one deg, respectively -- exactly what we want. And indeed below the peak, raise actions are all higher than lower actions and visa versa above the peak. Looks good.\n",
    "\n",
    "This game is really easy, and we've solved it. Nothing left to do. But for a harder task, we may want to avoid runaway rewards, change the `max` decision maker, or create more separation between good and bad decisions. It would be more gratifying/intuitive to see bad decisions get negative values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5effd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a37561bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "ax.scatter(episodes, rewards)\n",
    "\n",
    "plt.ylabel('average reward over 100 test showers')\n",
    "plt.xlabel('training episodes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a7898",
   "metadata": {},
   "source": [
    "### B. Find Optimal Training Parameters with a Grid Search <a name=\"grid_search\"></a>\n",
    "Search a 3D parameter space learning rate x discount rate x n training episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81cb76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62704a0",
   "metadata": {},
   "source": [
    "#### Do the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902e73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20x10x10 = 2000 trainings, many of them short\n",
    "param_grid = ParameterGrid({'alpha': np.arange(0., 1., 0.1).tolist(), \n",
    "                            'gamma': np.arange(0., 1., 0.1).tolist(), \n",
    "                            'n_episodes' : range(10,100,10)})\n",
    "alphas = defaultdict(list)\n",
    "gammas = defaultdict(list)\n",
    "rewards = defaultdict(list)\n",
    "for p in list(param_grid):\n",
    "    env = Shower()\n",
    "    q_table = train_test(env, init_q_table, n_episodes = p['n_episodes'], do_train = True, params=p)[0]\n",
    "    avg_reward = train_test(env, q_table, n_episodes = 100, do_train = False)[1]\n",
    "    alphas[p['n_episodes']].append(p['alpha'])\n",
    "    gammas[p['n_episodes']].append(p['gamma'])\n",
    "    rewards[p['n_episodes']].append(avg_reward)        \n",
    "    #print(f\"{e} training episodes – average reward: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6cad9d",
   "metadata": {},
   "source": [
    "#### plot rewards vs parameters\n",
    "with a slidebar for the number of trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220294d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of IPython.core.interactiveshell failed: Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: __class__ assignment: 'PickleShareDB' object layout differs from 'PickleShareDB'\n",
      "]\n",
      "[autoreload of typing_extensions failed: Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/typing_extensions.py\", line 740, in <module>\n",
      "    class SupportsAbs(Protocol[T_co]):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/typing.py\", line 309, in inner\n",
      "    return cached(*args, **kwds)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/typing.py\", line 1346, in __class_getitem__\n",
      "    return _GenericAlias(cls, params,\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/typing.py\", line 1025, in __init__\n",
      "    self.__parameters__ = _collect_type_vars(params, typevar_types=_typevar_types)\n",
      "NameError: name '_is_unpack' is not defined\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type, a tuple of types, or a union",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3302\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[0m\n\u001b[1;32m   3298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error_before_exec(e)\n\u001b[1;32m   3300\u001b[0m \u001b[38;5;66;03m# Give the displayhook a reference to our ExecutionResult so it\u001b[39;00m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;66;03m# can fill in the output value.\u001b[39;00m\n\u001b[0;32m-> 3302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplayhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_result\u001b[49m \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m   3304\u001b[0m \u001b[38;5;66;03m# Execute the user code\u001b[39;00m\n\u001b[1;32m   3305\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/traitlets/traitlets.py:718\u001b[0m, in \u001b[0;36mTraitType.__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraitError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m trait is read-only.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/traitlets/traitlets.py:691\u001b[0m, in \u001b[0;36mTraitType.set\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: HasTraits, value: S) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/traitlets/traitlets.py:724\u001b[0m, in \u001b[0;36mTraitType._validate\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 724\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_cross_validation_lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross_validate(obj, value)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/sb3/lib/python3.10/site-packages/traitlets/traitlets.py:2311\u001b[0m, in \u001b[0;36mInstance.validate\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_none \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m-> 2311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mklass\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# type:ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mcast(T, value)\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type, a tuple of types, or a union"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from ipywidgets import interact,widgets,fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4cce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperparams_grid(n_episodes, data_x, data_y, data_z):\n",
    "    f, ax = plt.subplots(figsize=(8,6))\n",
    "    \n",
    "    graph_x = data_x[n_episodes]\n",
    "    graph_y = data_y[n_episodes]\n",
    "    graph_z = data_z[n_episodes]\n",
    "    \n",
    "    # marker sizes - 1 invisible, 10 very small, 100 small, 5000 very big,  \n",
    "    size_list=np.array(graph_z)\n",
    "    size_list = [5e-12*(i+60)**7 for i in size_list]\n",
    "    \n",
    "    points=ax.scatter(graph_x, graph_y, c=graph_z, cmap='viridis',vmin=0,vmax=60,marker='o',s=size_list)\n",
    "    cbar=plt.colorbar(points)\n",
    "    cbar.set_label(\"Rewards\", fontsize=14)\n",
    "    ax.set_xlabel(r'$\\alpha$ - learning rate',fontsize=14)\n",
    "    ax.set_ylabel(r'$\\gamma$ - discount rate',fontsize=14)\n",
    "    ax.set_yticks(np.arange(0,1,.1))\n",
    "    ax.set_xticks(np.arange(0,1,.1))\n",
    "    ax.set_title(f\"Parameter space at {n_episodes} training episodes\")\n",
    "    plt.show()\n",
    "\n",
    "plot_hyperparams_grid(80,alphas,gammas,rewards)\n",
    "    \n",
    "interact(\n",
    "        plot_hyperparams_grid,\n",
    "        n_episodes = widgets.SelectionSlider(description='train length', options = list(alphas.keys())), \n",
    "        data_x = fixed(alphas), \n",
    "        data_y = fixed(gammas),\n",
    "        data_z = fixed(rewards)\n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff33595",
   "metadata": {},
   "source": [
    "#### And what's the best training parameter pair given each training length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a0e20fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_training episodes | max reward | alpha | gamma\n",
      "                 10 |      37.26 |   0.9 |   0.8\n",
      "                 20 |      55.20 |   0.9 |   0.9\n",
      "                 30 |      55.02 |   0.8 |   0.8\n",
      "                 40 |      55.36 |   0.9 |   0.9\n",
      "                 50 |      55.42 |   0.7 |   0.9\n",
      "                 60 |      55.06 |   0.8 |   0.5\n",
      "                 70 |      55.72 |   0.7 |   0.9\n",
      "                 80 |      55.26 |   0.8 |   0.5\n",
      "                 90 |      56.00 |   0.3 |   0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"n_training episodes | max reward | alpha | gamma\")\n",
    "for training, reward in rewards.items():\n",
    "    max_reward = max(reward)\n",
    "    alpha = alphas[training][reward.index(max(reward))]\n",
    "    gamma = gammas[training][reward.index(max(reward))]\n",
    "    print(f'{training:19} | {max_reward:10.2f} | {alpha:5.1f} | {gamma:5.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587eed7",
   "metadata": {},
   "source": [
    "#### Seems like some of these are statistical flukes.  alpha, gamma = 1,1 clearly performs best across all n_trainings"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/python",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
